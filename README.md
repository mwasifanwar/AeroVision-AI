# ğŸš AeroVision-AI  
### _Intelligent Aerial Vehicle Detection, Tracking & Analytics System_

> âœ¨ **AeroVision-AI** is a next-generation **aerial intelligence framework** built to understand the world from above.  
> It leverages the power of **YOLOv8**, **OpenCV**, and **Streamlit** to perform real-time **vehicle detection**, **object tracking**, and **data-driven analytics** on drone-captured footage â€” turning raw aerial video into meaningful, structured insight.

---

## ğŸ§  What It Does

AeroVision-AI goes far beyond traditional detection scripts â€” it acts as a **complete end-to-end visual intelligence system**.  
Using deep learning and advanced computer vision, it detects moving vehicles from drone footage, tracks them persistently with unique IDs, and generates **interactive, analytics-rich visualizations** that can be exported as videos, snapshots, and structured CSV reports.

The system is designed with a **research-grade backbone** and a **presentation-ready frontend**, allowing users to seamlessly explore data while maintaining production-level polish.

---

## ğŸš€ Key Idea

The core philosophy behind AeroVision-AI is simple yet powerful:  
> â€œTransform every aerial frame into an intelligent data point.â€

Whether youâ€™re analyzing parking lots, inspecting road traffic, monitoring events, or studying autonomous driving patterns â€” AeroVision-AI captures, interprets, and quantifies movement in a way that feels effortless and visually engaging.

---

## ğŸ§© Why It Stands Out

ğŸ’¡ **Deep Intelligence** â€” Built on **YOLOv8**, AeroVision-AI ensures high accuracy across diverse aerial angles, altitudes, and lighting conditions.  
ğŸ§­ **Persistent Tracking** â€” Each vehicle is tracked with consistent IDs, making it ideal for time-based analytics and behavioral observation.  
ğŸ“Š **Analytics-Driven Design** â€” Every frame contributes to measurable insights â€” detections, counts, movement trends, and positional data â€” stored neatly in exportable CSVs.  
ğŸ¨ **Streamlit-Powered UI** â€” A beautifully minimal, fully interactive interface to control confidence thresholds, IOU settings, watermark styling, and video recording â€” no coding needed.  
ğŸ’§ **Dynamic Watermark Layer** â€” Add your own branded watermark that tiles, rotates, and blends naturally into each processed frame.  
ğŸ“¦ **Research & Reporting Ready** â€” Perfect for demonstrations, traffic analysis, surveillance research, or AI showcase projects.  

---

## ğŸŒ The Vision

In a world where drones capture terabytes of video every day, **AeroVision-AI** turns those pixels into purpose.  
It empowers developers, researchers, and organizations to **see patterns in motion**, quantify behavior, and build smarter aerial ecosystems.

Through intelligent automation and elegant visualization, AeroVision-AI redefines how aerial data is perceived â€”  
from raw videoâ€¦ to **real-time visual intelligence**.  

---

> ğŸ§© **Built for innovation, designed for insight, and engineered for impact.**


## ğŸ“¸ Project Overview

**AeroVision-AI** is more than just a car detection script â€” itâ€™s a **complete aerial intelligence ecosystem** that brings drone footage to life through deep learning.  
At its core, the system can **detect, track, and analyze vehicles** in real time, transforming ordinary drone videos into rich visual data streams filled with actionable insights.

Using a combination of **YOLOv8**, **OpenCV**, and **Streamlit**, AeroVision-AI enables users to experience the power of aerial analytics through an intuitive interface and professional-grade outputs.

It empowers you to:
- ğŸ›£ï¸ **Monitor and analyze** traffic patterns, parking areas, or event zones from an aerial perspective  
- ğŸ”¢ **Automatically count and track** every detected vehicle with persistent IDs  
- ğŸï¸ **Export annotated videos** complete with bounding boxes and labeled tracks  
- ğŸ“Š **Generate detailed CSV analytics** for research, reporting, or data modeling  
- ğŸ’§ **Apply branded watermark overlays** to maintain visual ownership and authenticity  

In essence, AeroVision-AI bridges **drone vision and data intelligence**, turning raw footage into structured, insightful visual evidence for researchers, developers, and analysts alike.

---

## âš™ï¸ Core Features

| ğŸŒŸ Feature | ğŸ’¡ Description |
|-------------|----------------|
| ğŸ¥ **Real-time YOLOv8 Inference** | Utilizes the state-of-the-art YOLOv8 object detection model to identify vehicles across frames instantly with remarkable accuracy. |
| ğŸ§­ **Intelligent Object Tracking** | Tracks every detected car persistently using an IOU-based tracker, ensuring consistent IDs and smooth temporal continuity across the video stream. |
| ğŸ“Š **Analytical Data Export** | Automatically logs detections into structured CSV files containing frame indices, bounding box coordinates, confidence levels, and class information. |
| ğŸ’§ **Dynamic Watermark System** | Add customizable, semi-transparent watermark layers with adjustable opacity, rotation, and spacing â€” ensuring secure and professional outputs. |
| ğŸ’¾ **Video & Snapshot Recording** | Capture fully processed videos or individual frames as images â€” ideal for research presentations or academic reports. |
| ğŸ§© **Streamlit Interactive Dashboard** | A clean, user-friendly dashboard to upload footage, tweak parameters, and visualize results live â€” all without writing a single line of code. |
| âš¡ **Optimized Performance** | Efficient inference pipeline optimized for both GPU and CPU, allowing smooth operation even on modest setups. |
| ğŸ§¾ **Automated Output Management** | Each run is automatically organized into time-stamped folders, keeping all MP4, CSV, and snapshot outputs cleanly structured and easy to access. |

---

> ğŸ§  **In short:** AeroVision-AI transforms aerial visuals into measurable intelligence â€” making drones not just eyes in the sky, but analysts in motion.


## ğŸ§© Architecture Overview

The architecture of **AeroVision-AI** is designed with a clear goal â€” to create a **seamless, modular, and interpretable pipeline** that transforms raw drone footage into structured, visual, and analytical intelligence.  
Every layer of the system communicates efficiently, ensuring real-time inference, clean visualization, and effortless data export â€” all orchestrated within an elegant Streamlit interface.

<p align="center">
  <img src="./reports/architecture.png" width="700" alt="AeroVision-AI Architecture Diagram"/>
</p>

---

### ğŸ§  How It Works

At its core, the system follows a **modular service-based architecture**, where each component focuses on a distinct responsibility â€” from frame ingestion to analytics generation.  
This design not only ensures scalability and clarity but also allows developers and researchers to extend or replace modules with minimal effort.

---

### ğŸ”¹ **Detailed Data Flow**

1. ğŸ–¥ï¸ **Streamlit Frontend (`streamlit_app/app.py`)**  
   Acts as the user interface and control center. Users upload drone footage or images, set detection thresholds, choose watermark preferences, and monitor outputs live.  

2. ğŸ§  **YOLOv8 Detector (`src/detector.py`)**  
   Processes each incoming frame using **YOLOv8**, performing real-time vehicle detection with high confidence and precision.  
   It outputs bounding boxes, class IDs, and confidence scores for each detected object.

3. ğŸ§­ **Tracker Module (`src/tracker.py`)**  
   Uses an **IOU (Intersection over Union)**-based algorithm to maintain identity consistency across frames.  
   Each car receives a unique tracking ID, ensuring smooth object association even in overlapping or fast-moving scenes.

4. ğŸ¨ **Visualization Engine (`src/viz.py`)**  
   Handles real-time drawing of bounding boxes, track IDs, and overlay elements such as FPS counters and watermark layers.  
   Ensures processed frames are both informative and presentation-ready.

5. ğŸ’¾ **Export Services**  
   Captures processed frames and writes them as:
   - ğŸ¥ Annotated videos (`.mp4`)
   - ğŸ“Š Analytics CSV logs (`.csv`)
   - ğŸ–¼ï¸ Snapshots (`.png`)  
   All outputs are stored neatly in the `/outputs` directory, automatically organized by timestamp.

6. ğŸ“ **Reporting & Analysis Layer (`/reports`)**  
   Aggregates key visualizations, architecture references, and summary snapshots that can be used for academic documentation, performance reports, or presentations.

---

### âš™ï¸ Architectural Principles

| Principle | Description |
|------------|-------------|
| ğŸ§© **Modularity** | Each function (detection, tracking, visualization) is isolated yet interconnected â€” easy to extend or upgrade individually. |
| âš¡ **Real-Time Performance** | The entire pipeline is optimized for live frame-by-frame inference without noticeable lag, even on CPUs. |
| ğŸ“ˆ **Traceability** | Every processed frame, detection, and track is stored and can be audited or analyzed later for reproducibility. |
| ğŸ’¡ **Scalability** | New modules (e.g., multi-class detection, speed estimation) can be integrated with minimal code restructuring. |
| ğŸ§¾ **Transparency** | A clear, human-readable code structure allows researchers and developers to easily follow and explain each stage of the process. |

---

In summary, **AeroVision-AIâ€™s architecture** is not just a collection of scripts â€”  
itâ€™s a **living ecosystem of interconnected components**, purpose-built to bridge drone vision and data science.  
Each frame enters as raw imagery and exits as **interpretable intelligence**, ready for visualization, reporting, or further AI modeling.


## ğŸ—‚ï¸ Directory Structure

AeroVision-AI follows a **clean, modular project structure**, ensuring clarity, scalability, and maintainability.  
Each directory serves a distinct role in the pipeline â€” from deep learning inference to visualization and reporting.

AeroVision-AI/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detector.py              # âš™ï¸ YOLOv8-based vehicle detection service
â”‚   â”œâ”€â”€ tracker.py               # ğŸ¯ IOU-based object tracking module
â”‚   â”œâ”€â”€ viz.py                   # ğŸ–¼ï¸ Frame drawing, watermarking & export utilities
â”‚   â””â”€â”€ __init__.py              # Initializes the src module
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ app.py                   # ğŸ§© Streamlit frontend for user interaction & visualization
â”‚
â”œâ”€â”€ outputs/                     # ğŸ’¾ Automatically saved processed videos, CSVs, and snapshots
â”‚
â”œâ”€â”€ reports/                     # ğŸ“Š Stored screenshots, architecture diagrams, and performance visuals
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov8n.pt               # ğŸ¤– Pre-trained YOLOv8 Nano model for inference
â”‚
â”œâ”€â”€ requirements.txt             # ğŸ“¦ List of dependencies for environment setup
â”œâ”€â”€ architecture.png             # ğŸ§  System architecture diagram (used in documentation)
â””â”€â”€ README.md                    # ğŸ“˜ Project documentation file

### ğŸ“ Directory Purpose Summary

| ğŸ—‚ï¸ **Folder / File** | ğŸ§© **Description** |
|------------------------|--------------------|
| **`src/`** | Core backend containing detection, tracking, and visualization logic. |
| **`streamlit_app/`** | Frontend layer for user uploads, parameter control, and live results display. |
| **`outputs/`** | Stores all generated outputs â€” annotated videos, CSV analytics, and saved frames. |
| **`reports/`** | Includes documentation visuals, screenshots, and research-ready figures. |
| **`models/`** | Houses pre-trained weights or custom model checkpoints for YOLOv8. |
| **`requirements.txt`** | Defines all project dependencies for environment setup. |
| **`architecture.png`** | High-level architecture overview diagram used in documentation. |
| **`README.md`** | The main project guide (this file). |

---

## ğŸ§  Tech Stack

**AeroVision-AI** leverages a **modern, efficient, and research-friendly technology stack**, blending the flexibility of Python with state-of-the-art AI libraries for computer vision, analytics, and UI development.

| ğŸ§© **Category** | âš™ï¸ **Technologies Used** | ğŸ§  **Purpose** |
|-----------------|--------------------------|----------------|
| ğŸ¨ **Frontend / UI** | **Streamlit** | Builds an interactive dashboard for real-time visualization and parameter control. |
| ğŸ¤– **Core ML Model** | **YOLOv8 (Ultralytics)** | Performs high-speed, high-accuracy vehicle detection in aerial frames. |
| ğŸ§­ **Vision Processing** | **OpenCV**, **NumPy** | Handles image transformations, video frame operations, and pixel-level processing. |
| ğŸ¯ **Tracking Engine** | **IOU-based Tracker** | Maintains consistent tracking IDs across frames for accurate motion analysis. |
| ğŸ“Š **Visualization Layer** | **Matplotlib**, **OpenCV** | Renders bounding boxes, tracks, FPS counters, and dynamic watermark overlays. |
| ğŸ“ˆ **Data Handling** | **CSV**, **Tempfile** | Stores analytical data, tracks detections, and supports file streaming. |
| âš™ï¸ **Backend Logic** | **Python 3.10+** | Provides overall orchestration, module integration, and environment compatibility. |

---

> ğŸ§  **In short:**  
> The AeroVision-AI tech stack is engineered for **speed, modularity, and interpretability**, making it ideal for research, prototyping, and real-world drone analytics.

## ğŸš€ Setup & Installation

Follow these steps to set up and run **AeroVision-AI** on your local machine.  
The setup process is designed to be simple, portable, and consistent across all operating systems.

---

### ğŸ§© 1ï¸âƒ£ Clone the Repository

Start by cloning the repository and navigating into the project directory:

git clone https://github.com/mwasifanwar/AeroVision-AI.git
cd AeroVision-AI

âš™ï¸ 2ï¸âƒ£ Create a Virtual Environment

Create and activate a virtual environment to keep dependencies isolated and clean:

# Create virtual environment
python -m venv .venv

# Activate (Linux / macOS)
source .venv/bin/activate

# Activate (Windows)
.venv\Scripts\activate


ğŸ“¦ 3ï¸âƒ£ Install Dependencies

Install all required Python packages using requirements.txt

pip install -r requirements.txt

This will automatically install the core dependencies:

ğŸ¤– YOLOv8 (Ultralytics) â†’ Object detection engine

ğŸ§­ OpenCV â†’ Video and image processing

ğŸ¨ Streamlit â†’ Interactive dashboard framework

ğŸ§® NumPy, Matplotlib â†’ Numerical operations and visualization tools

ğŸ§  4ï¸âƒ£ Run the Streamlit App

Launch the application using Streamlit:
streamlit run streamlit_app/app.py


## ğŸ® Usage

Using **AeroVision-AI** is straightforward â€” no coding required!  
Simply follow these steps inside the **Streamlit interface**:

---

### ğŸª¶ Step-by-Step Workflow

1. **Launch the App**
   - Run the app using the command:
     ```bash
     streamlit run streamlit_app/app.py
     ```

2. **Upload Your Media**
   - ğŸ¥ **Drone Videos:** `.mp4`, `.avi`, `.mov`  
   - ğŸ–¼ï¸ **Still Images:** `.jpg`, `.jpeg`, `.png`

3. **Adjust Parameters**
   - ğŸ” **Detection Confidence:** Filter out low-confidence predictions for cleaner results.  
   - ğŸ¯ **IOU Threshold:** Tune the trackerâ€™s sensitivity to maintain smoother and more consistent object IDs.  
   - ğŸ’§ **Watermark Settings:** Customize text, opacity, angle, and spacing to match your branding or report style.

4. **Start Detection**
   - Press **â–¶ï¸ Start** to begin real-time inference and object tracking.  
   - The system processes frames dynamically, applying YOLOv8 detections and tracking IDs to each vehicle.

5. **Visualize Results Live**
   - Watch **detections, bounding boxes, IDs, and FPS counters** update frame-by-frame in real time on the Streamlit dashboard.  
   - Easily toggle between modes, adjust confidence levels, and fine-tune visualization without restarting.

6. **Export Outputs**
   - ğŸ’¾ **Processed Video (.mp4):** Includes bounding boxes, track IDs, and optional watermark overlay.  
   - ğŸ“Š **Detections CSV (.csv):** Contains detailed analytics including frame index, object ID, class label, confidence score, and bounding box coordinates.  
   - ğŸ–¼ï¸ **Snapshots (.png):** Saves static frames for documentation, research reports, or presentations.

---

## ğŸ“Š Output Samples

All generated visuals and analytical results from **AeroVision-AI** are automatically stored inside the `outputs/` folder after each session.  
Additionally, curated screenshots are placed in the `reports/` directory for documentation and research presentation.

---

### ğŸ–¼ï¸ Example Outputs

| Example | Description |
|----------|-------------|
| ğŸ–¼ï¸ `reports/01.png` | Drone overview showcasing multiple vehicles detected simultaneously using YOLOv8. |
| ğŸ–¼ï¸ `reports/02.png` | Persistent **tracking** view â€” each vehicle maintains a unique ID across frames. |
| ğŸ–¼ï¸ `reports/03.png` | Custom **watermark overlay** applied to ensure brand identity and professional presentation. |
| ğŸ–¼ï¸ `reports/04.png` | **CSV-exported analytics preview** displaying structured detection and tracking data. |
| ğŸ–¼ï¸ `reports/05.png` | Final **visualization snapshot**, ideal for reports, demonstrations, or publications. |

---

### ğŸ“¸ Visual Preview

<p align="center">
  <img src="reports/01.png" width="700" alt="AeroVision-AI Sample Output 1"/>
</p>

<p align="center">
  <i>Example: Real-time vehicle detection and tracking from aerial footage using YOLOv8.</i>
</p>

<p align="center">
  <img src="reports/03.png" width="700" alt="AeroVision-AI Sample Output 1"/>
</p>

<p align="center">
  <img src="reports/04.png" width="700" alt="AeroVision-AI Sample Output 1"/>
</p>

## ğŸ“ˆ Analytics & Export

**AeroVision-AI** automatically logs every detection and tracking event into structured **CSV files**, enabling seamless analysis and post-processing.  
Each frame processed during video inference generates a corresponding entry that includes bounding box coordinates, object IDs, class labels, and confidence values.

---

### ğŸ§® CSV Output Structure

Each CSV file follows a standardized format for easy integration with **Python**, **Excel**, or **Power BI**:

| Frame | Track ID | Class | Confidence | X1 | Y1 | X2 | Y2 |
|--------|-----------|--------|-------------|----|----|----|----|
| 132 | 7 | car | 0.94 | 380 | 200 | 420 | 250 |

---

### ğŸ’¡ How It Works
- For **every frame** in your uploaded video, **YOLOv8** performs object detection.  
- The **IOU-based tracker** assigns a **unique Track ID** to each vehicle and maintains its identity across frames.  
- The system records all detections into a **CSV** file, stored automatically in the `/outputs` folder.  
- The result is a **chronological detection log** that can be visualized, aggregated, or used for model fine-tuning and downstream analytics.

---

### ğŸ§  Why Itâ€™s Powerful

- âœ… **Quantitative Insight:** Transform raw drone footage into measurable data points.  
- âœ… **Versatile Integration:** Import CSVs into Python (Pandas), Excel, Tableau, or Power BI.  
- âœ… **Research-Ready:** Ideal for academic analysis, traffic pattern studies, or dataset creation.  
- âœ… **Automation Friendly:** Supports batch processing and consistent export structure.

> ğŸ“Š **Example Use Case:**  
> - Compute traffic density per frame.  
> - Plot vehicle trajectories over time.  
> - Generate heatmaps for congestion analysis.  

---

## ğŸŒ Future Enhancements

The roadmap for **AeroVision-AI** includes several planned upgrades to elevate functionality, performance, and scalability.  
These features aim to make the platform more powerful for both research and real-world deployments.

---

| Feature | Description |
|----------|-------------|
| ğŸ“¦ **Speed Estimation** | Compute approximate vehicle speed using frame-to-frame position differentials and FPS data. |
| ğŸ§­ **Zone Counting** | Define polygonal or rectangular regions in the video to count vehicle entry and exit events. |
| â˜ï¸ **Web Deployment** | Deploy directly on platforms like **Hugging Face Spaces**, **Render**, or **Streamlit Cloud** for public demos. |
| ğŸ” **Multi-Class Support** | Extend model capabilities beyond cars to include trucks, motorbikes, and pedestrians. |
| ğŸ§  **SHAP / LIME Explainability** | Integrate interpretability modules to visualize how the model makes decisions (explainable AI). |
| ğŸ“Š **Real-time Dashboard** | Add live analytical visualization (charts, graphs, traffic density meters) using **Plotly** or **Dash**. |

---

### ğŸš€ Planned Technical Extensions

1. **MLOps Integration:** Automate retraining pipelines using Docker + GitHub Actions.  
2. **Edge Optimization:** Quantize YOLOv8 for real-time deployment on Jetson or Raspberry Pi.  
3. **Cloud Storage Sync:** Auto-upload processed outputs to Google Drive / S3.  
4. **REST API Endpoint:** Serve live predictions via FastAPI for third-party integration.  
5. **UI Enhancements:** Add interactive analytics, filter controls, and report builders within Streamlit.

---

> ğŸ§© **In summary:**  
> The foundation of **AeroVision-AI** is designed with modular extensibility â€” enabling future upgrades without breaking the existing architecture.  
> Itâ€™s not just a drone detection system; itâ€™s an evolving framework for **intelligent aerial analytics**.

<br>

<h2 align="center">âœ¨ Author</h2>

<p align="center">
  <b>Muhammad Wasif</b><br>
 AI/ML Developer â€¢ Founder @ Effixly AI
</p>

<p align="center">
  <a href="https://www.linkedin.com/in/mwasifanwar" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin" alt="LinkedIn">
  </a>
  <a href="mailto:wasifsdk@gmail.com">
    <img src="https://img.shields.io/badge/Email-grey?style=for-the-badge&logo=gmail" alt="Email">
  </a>
  <a href="https://mwasif.dev" target="_blank">
    <img src="https://img.shields.io/badge/Website-black?style=for-the-badge&logo=google-chrome" alt="Website">
  </a>
</p>

<p align="center">
  <em>"Predicting churn isnâ€™t just about saving customers â€” itâ€™s about understanding them."</em>  
</p>

<br>
